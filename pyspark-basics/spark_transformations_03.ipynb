{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .appName(\"Hello Spark\") \\\n",
    "                    .master(\"local[2]\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_df = spark.read \\\n",
    "            .format(\"csv\") \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .option(\"inferSchema\", \"true\").load(\"spark_transformations_03.csv\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+----+----------+-----+\n",
      "|     day|    city|temp|wind speed|event|\n",
      "+--------+--------+----+----------+-----+\n",
      "|20110014|new york|  23|         6| rain|\n",
      "|20110014|new york|  24|         7|sunny|\n",
      "|20110014|new york|  25|         8|rainy|\n",
      "|20110014|new york|  26|         9| rain|\n",
      "|20110014|new york|  27|        10| rain|\n",
      "|20110014|  mumbai|  28|        11|sunny|\n",
      "|20110014|  mumbai|  29|        12|rainy|\n",
      "|20110014|  mumbai|  30|        13| snow|\n",
      "|20110014|  mumbai|  31|        14| snow|\n",
      "|20110014|  mumbai|  32|        15| rain|\n",
      "|20110014|  mumbai|  33|        16|sunny|\n",
      "|20110014|   paris|  34|        17|rainy|\n",
      "|20110014|   paris|  34|        17|rainy|\n",
      "|20110014|   paris|  34|        17|rainy|\n",
      "|20110014|   paris|  34|        17|rainy|\n",
      "+--------+--------+----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove the spaces from the column names\n",
    "# Note : 1. You can create a chain of spark transformation methods  one after the another. \n",
    "# 2. Spark transformations returns new dataframes after transforming the old dataframe\n",
    "# 3. Spark Dataframe is immutable\n",
    "# 4. Spark data like columns names are case insensitive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_fire_df = fire_df \\\n",
    "                    .withColumnRenamed(\"wind speed\", \"windspeed\") \\\n",
    "                    .withColumnRenamed(\"event\", \"Events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+----+---------+------+\n",
      "|     day|    city|temp|windspeed|Events|\n",
      "+--------+--------+----+---------+------+\n",
      "|20110014|new york|  23|        6|  rain|\n",
      "|20110014|new york|  24|        7| sunny|\n",
      "|20110014|new york|  25|        8| rainy|\n",
      "|20110014|new york|  26|        9|  rain|\n",
      "|20110014|new york|  27|       10|  rain|\n",
      "|20110014|  mumbai|  28|       11| sunny|\n",
      "|20110014|  mumbai|  29|       12| rainy|\n",
      "|20110014|  mumbai|  30|       13|  snow|\n",
      "|20110014|  mumbai|  31|       14|  snow|\n",
      "|20110014|  mumbai|  32|       15|  rain|\n",
      "|20110014|  mumbai|  33|       16| sunny|\n",
      "|20110014|   paris|  34|       17| rainy|\n",
      "|20110014|   paris|  34|       17| rainy|\n",
      "|20110014|   paris|  34|       17| rainy|\n",
      "|20110014|   paris|  34|       17| rainy|\n",
      "+--------+--------+----+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rename_fire_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- day: integer (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- temp: integer (nullable = true)\n",
      " |-- windspeed: integer (nullable = true)\n",
      " |-- Events: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rename_fire_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change the data type of any of the columns like Day field to date datatype`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = rename_fire_df.withColumn(\"day\", to_date(\"day\", \"yyyy-MM-dd \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- day: date (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- temp: integer (nullable = true)\n",
      " |-- windspeed: integer (nullable = true)\n",
      " |-- Events: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[day: date, city: string, temp: int, windspeed: int, Events: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+----+---------+------+\n",
      "| day|    city|temp|windspeed|Events|\n",
      "+----+--------+----+---------+------+\n",
      "|NULL|new york|  23|        6|  rain|\n",
      "|NULL|new york|  24|        7| sunny|\n",
      "|NULL|new york|  25|        8| rainy|\n",
      "|NULL|new york|  26|        9|  rain|\n",
      "|NULL|new york|  27|       10|  rain|\n",
      "|NULL|  mumbai|  28|       11| sunny|\n",
      "|NULL|  mumbai|  29|       12| rainy|\n",
      "|NULL|  mumbai|  30|       13|  snow|\n",
      "|NULL|  mumbai|  31|       14|  snow|\n",
      "|NULL|  mumbai|  32|       15|  rain|\n",
      "|NULL|  mumbai|  33|       16| sunny|\n",
      "|NULL|   paris|  34|       17| rainy|\n",
      "|NULL|   paris|  34|       17| rainy|\n",
      "|NULL|   paris|  34|       17| rainy|\n",
      "|NULL|   paris|  34|       17| rainy|\n",
      "+----+--------+----+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying dataframes : \n",
    "# 1. Uisng Sql - you have to convert dataframes into te,porary view then run your sql queries on the views. for eg - \n",
    "# new_df.createOrReplaceTempView(\"view_name\")\n",
    "ql_sql = spark.sql (\"\"\"\n",
    "    select distinct(city) from view_name\n",
    "\"\"\")\n",
    "display (ql_sql)\n",
    "# 2. Dataframe transformation approach \n",
    "# Dataframe Transformation methods : where(), select(), distinct(), count().\n",
    "# Dataframe Actions methods : count(), show()\n",
    "# Dataframe Functions methods : expr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "ql_df = new_df.where(\"city is not null\") \\\n",
    "            .select(expr(\"city as Distinct_City\")) \\\n",
    "            .distinct()\n",
    "print(ql_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    city|\n",
      "+--------+\n",
      "|new york|\n",
      "|   paris|\n",
      "|  mumbai|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ql_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+----+------+\n",
      "|Distinct_City|windspeed|temp|events|\n",
      "+-------------+---------+----+------+\n",
      "|        paris|       17|  34| rainy|\n",
      "|       mumbai|       14|  31|  snow|\n",
      "|       mumbai|       16|  33| sunny|\n",
      "|       mumbai|       15|  32|  rain|\n",
      "+-------------+---------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ql_df_1 = new_df.where(\"city is not null And temp >30\") \\\n",
    "            .select(expr(\"city as Distinct_City\"), \"windspeed\", \"temp\", \"events\") \\\n",
    "            .distinct() \\\n",
    "            .show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+----+------+\n",
      "|Distinct_City|windspeed|temp|events|\n",
      "+-------------+---------+----+------+\n",
      "|        paris|       17|  34| rainy|\n",
      "|        paris|       17|  34| rainy|\n",
      "|        paris|       17|  34| rainy|\n",
      "|        paris|       17|  34| rainy|\n",
      "|       mumbai|       16|  33| sunny|\n",
      "|       mumbai|       15|  32|  rain|\n",
      "|       mumbai|       14|  31|  snow|\n",
      "+-------------+---------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.select(expr(\"city as Distinct_City\"), \"windspeed\", \"temp\", \"events\") \\\n",
    "    .where(\"city is not null And temp >30\") \\\n",
    "    .orderBy(\"temp\", ascending=False) \\\n",
    "    .show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
