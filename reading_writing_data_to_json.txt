============================================== writing data to json =================================
import json
import pandas as pd
import sqlalchemy
from sqlalchemy.engine.url import URL
 
 
# create a function to connect to the database
def connect():
    # build the sqlalchemy URL
    url = URL.create(
        drivername='redshift+redshift_connector',  # indicate redshift_connector driver and dialect will be used
        host='ri-qa-redshift-serverless-wrkgrp.072803948741.us-east-1.redshift-serverless.amazonaws.com',
        # Amazon Redshift host
        port=5439,  # Amazon Redshift port
        database='ri_client2',  # Amazon Redshift database
        username='nitsachdeva',  # Amazon Redshift username
        password='Welcome1'  # Amazon Redshift password
    )
    con = sqlalchemy.create_engine(url)
    return con
 
 
def execute_query():
    query = '''
    with cte_rmt as (select rmt.acct_dim_pkey, sum(rmt.denied_dollars) as "denied_dollars" from dm.vw_bi_remits rmt group by rmt.acct_dim_pkey)
    select count(distinct acct.acct_dim_pkey) as "count_of_accounts", sum(acct.tot_chrgs) as "gross_charges", sum(acct.crrnt_expctd_rmbrsmnt) as "net_payment_expected",
    sum(rmt."denied_dollars") as "denied_dollars", sum(acct.latest_tot_pmnts) as "total_payments", sum(acct.latest_current_acct_bal) as "total_balance"
    from dm.vw_bi_accounts acct left join cte_rmt rmt on rmt.acct_dim_pkey = acct.acct_dim_pkey
    '''
    return query
 
 
if __name__ == '__main__':
    try:
        # connect to the database
        engine = connect()
        print('Connected to the database')
 
        # read the data from sql table
        sql_query1 = execute_query()
 
        df1 = pd.read_sql(sql_query1, engine)
       
        df.to_json("demo.json", orient='records')
        existing_data = pd.read_json("demo.json")
 
 
        sql_query2 = execute_query()
        df2 = pd.read_sql(sql_query2, engine)
        print(df2)
       
        combined_data = pd.concat([existing_data, df2], ignore_index=True)
        combined_data.to_json("demo.json", orient='records')
 
    # verify while writing data to csv , append the data when next time data is written
    # df.to_csv("demo.csv", index=False)
 
    except Exception as e:
        print(e)
        print('Error in reading the data from the table')
 
    finally:
    # close the database connection
        engine.dispose()
        print('Database connection closed')


============================================== updating data to json with multiple scenario exxecution =================================
import json
import pandas as pd
import sqlalchemy
from sqlalchemy.engine.url import URL


# create a function to connect to the database
def connect():
    # build the sqlalchemy URL
    url = URL.create(
        drivername='redshift+redshift_connector',  # indicate redshift_connector driver and dialect will be used
        host='ri-qa-redshift-serverless-wrkgrp.072803948741.us-east-1.redshift-serverless.amazonaws.com',
        # Amazon Redshift host
        port=5439,  # Amazon Redshift port
        database='ri_client2',  # Amazon Redshift database
        username='nitsachdeva',  # Amazon Redshift username
        password='Welcome1'  # Amazon Redshift password
    )
    con = sqlalchemy.create_engine(url)
    return con


def execute_query():
    query = '''
    with cte_rmt as (select rmt.acct_dim_pkey, sum(rmt.denied_dollars) as "denied_dollars" from dm.vw_bi_remits rmt group by rmt.acct_dim_pkey) 
    select count(distinct acct.acct_dim_pkey) as "count_of_accounts", sum(acct.tot_chrgs) as "gross_charges", sum(acct.crrnt_expctd_rmbrsmnt) as "net_payment_expected",
    sum(rmt."denied_dollars") as "denied_dollars", sum(acct.latest_tot_pmnts) as "total_payments", sum(acct.latest_current_acct_bal) as "total_balance" 
    from dm.vw_bi_accounts acct left join cte_rmt rmt on rmt.acct_dim_pkey = acct.acct_dim_pkey
    '''
    return query


if __name__ == '__main__':
    try:
        # connect to the database
        engine = connect()
        print('Connected to the database')

        # scenario 1
        sql_query1 = execute_query()
        df1 = pd.read_sql(sql_query1, engine)
        data_root_key = {"ri_spec1": df1.to_dict(orient='records')}
        with open('demo.json', 'w') as f:
            json.dump(data_root_key, f)
      
	  # scenario 2
        sql_query2 = execute_query()
        df2 = pd.read_sql(sql_query2, engine)
        print(df2)
        data_scnd_root_key = {"ri_spec2": df2.to_dict(orient='records')}
        with open('demo.json', 'r') as f:
            existing_data = json.load(f)

        existing_data.update(data_scnd_root_key)

        with open('demo.json', 'w') as f:
            json.dump(existing_data, f)

    except Exception as e:
        print(e)
        print('Error in reading the data from the table')

    finally:
    # close the database connection
        engine.dispose()
        print('Database connection closed')


================================== making utilities of writing data to json =========================
import json
import pandas as pd
import sqlalchemy
from sqlalchemy.engine.url import URL


# create a function to connect to the database
def connect():
    # build the sqlalchemy URL
    url = URL.create(
        drivername='redshift+redshift_connector',  # indicate redshift_connector driver and dialect will be used
        host='ri-qa-redshift-serverless-wrkgrp.072803948741.us-east-1.redshift-serverless.amazonaws.com',
        # Amazon Redshift host
        port=5439,  # Amazon Redshift port
        database='ri_client2',  # Amazon Redshift database
        username='nitsachdeva',  # Amazon Redshift username
        password='Welcome1'  # Amazon Redshift password
    )
    con = sqlalchemy.create_engine(url)
    return con


def execute_query():
    query = '''
    with cte_rmt as (select rmt.acct_dim_pkey, sum(rmt.denied_dollars) as "denied_dollars" from dm.vw_bi_remits rmt group by rmt.acct_dim_pkey) 
    select count(distinct acct.acct_dim_pkey) as "count_of_accounts", sum(acct.tot_chrgs) as "gross_charges", sum(acct.crrnt_expctd_rmbrsmnt) as "net_payment_expected",
    sum(rmt."denied_dollars") as "denied_dollars", sum(acct.latest_tot_pmnts) as "total_payments", sum(acct.latest_current_acct_bal) as "total_balance" 
    from dm.vw_bi_accounts acct left join cte_rmt rmt on rmt.acct_dim_pkey = acct.acct_dim_pkey
    '''
    return query


def update_json_with_scenario(engine, query, scenario_name):
    try:
        # read the data from sql table
        df1 = pd.read_sql(query, engine)

        # add spec id to the data
        data_root_key = {scenario_name: df1.to_dict(orient='records')}

        # read the existing data from the json file
        with open('demo.json', 'r') as f:
            existing_data = json.load(f)

        # append data with spec id to the existing data
        existing_data.update(data_root_key)

        # write the updated data to the json file
        with open('demo.json', 'w') as f:
            json.dump(existing_data, f)

    except Exception as e:
        print(e)
        print('Error in reading/writing the data to/from json file')


if __name__ == '__main__':
    try:
        # connect to the database
        engine = connect()
        print('Connected to the database')

        # scenario 1
        sql_query1 = execute_query()
        update_json_with_scenario(engine, sql_query1, "ri_spec1")

        # scenario 2
        sql_query2 = execute_query()
        update_json_with_scenario(engine, sql_query2, "ri_spec2")



    except Exception as e:
        print(e)
        print('Error in reading the data from the table')

    finally:
        # close the database connection
        engine.dispose()
        print('Database connection closed')



======================================== importing account scenarios from json =========================

import pandas as pd
from sqlalchemy import create_engine
import json

def update_json_with_scenarios(engine, scenarios_file):
    # Read scenarios configuration from JSON file
    with open(scenarios_file, 'r') as f:
        scenarios_data = json.load(f)

    # Initialize list to hold data for all scenarios
    all_data = []

    # Iterate over all scenarios
    for scenario in scenarios_data["account_analysis_scenarios"]:
        # Retrieve scenario details
        root_key = scenario['root_key']
        query = scenario['query']

        # Retrieve Data Using SQLAlchemy
        data = pd.read_sql(query, engine)

        # Add Root Key to Data
        data_with_root_key = {root_key: data.to_dict(orient='records')}

        # Append Data with Root Key to list
        all_data.append(data_with_root_key)

    # Write Combined Data for all scenarios to JSON File
    with open('data.json', 'w') as f:
        json.dump(all_data, f)

# Example usage:
engine = create_engine('database_connection_string')
scenarios_file = 'scenarios_config.json'

update_json_with_scenarios(engine, scenarios_file)
